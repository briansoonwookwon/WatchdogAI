{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to follow\n",
    "\n",
    "- clome the mmdetection repo: https://github.com/open-mmlab/mmdetection\n",
    "- pip install -e . in the mmdetection directory\n",
    "- Change the file: mmdetection/configs/htc/htc_r50_fpn_1x_artifact.py\n",
    "\n",
    "\n",
    "python tools/train.py configs/htc/htc_r50_fpn_1x_artifact.py --cfg-options device=mps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Train images: 69\n",
      "Validation images: 25\n",
      "Test images: 10\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Paths to your COCO annotation files\n",
    "train_anno = '/Users/jbm/Documents/DSAN_6500/WatchdogAI/data_artifacts/train/_annotations.coco.json'\n",
    "valid_anno = '/Users/jbm/Documents/DSAN_6500/WatchdogAI/data_artifacts/valid/_annotations.coco.json'\n",
    "test_anno = '/Users/jbm/Documents/DSAN_6500/WatchdogAI/data_artifacts/test/_annotations.coco.json'\n",
    "\n",
    "# Load each dataset\n",
    "coco_train = COCO(train_anno)\n",
    "coco_valid = COCO(valid_anno)\n",
    "coco_test = COCO(test_anno)\n",
    "\n",
    "# Print number of images\n",
    "print(f\"Train images: {len(coco_train.getImgIds())}\")\n",
    "print(f\"Validation images: {len(coco_valid.getImgIds())}\")\n",
    "print(f\"Test images: {len(coco_test.getImgIds())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split complete. Test now has 10 images. Others redistributed to train and valid.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_dir = Path('/Users/jbm/Documents/DSAN_6500/WatchdogAI/data_artifacts/')\n",
    "train_path = base_dir / 'train/_annotations.coco.json'\n",
    "valid_path = base_dir / 'valid/_annotations.coco.json'\n",
    "test_path  = base_dir / 'test/_annotations.coco.json'\n",
    "\n",
    "# Load annotation files\n",
    "with open(train_path) as f:\n",
    "    train_data = json.load(f)\n",
    "with open(valid_path) as f:\n",
    "    valid_data = json.load(f)\n",
    "with open(test_path) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Shuffle and split test images\n",
    "random.seed(42)\n",
    "random.shuffle(test_data['images'])\n",
    "\n",
    "test_images = test_data['images'][:10]\n",
    "extra_images = test_data['images'][10:]\n",
    "\n",
    "# Get image ids to move\n",
    "extra_ids = {img['id'] for img in extra_images}\n",
    "test_ids = {img['id'] for img in test_images}\n",
    "\n",
    "# Separate corresponding annotations\n",
    "extra_annotations = [ann for ann in test_data['annotations'] if ann['image_id'] in extra_ids]\n",
    "test_annotations  = [ann for ann in test_data['annotations'] if ann['image_id'] in test_ids]\n",
    "\n",
    "# Split the extra images between train and val\n",
    "extra_val = extra_images[:6]\n",
    "extra_train = extra_images[6:]\n",
    "\n",
    "extra_val_ids = {img['id'] for img in extra_val}\n",
    "extra_train_ids = {img['id'] for img in extra_train}\n",
    "\n",
    "extra_val_annotations = [ann for ann in extra_annotations if ann['image_id'] in extra_val_ids]\n",
    "extra_train_annotations = [ann for ann in extra_annotations if ann['image_id'] in extra_train_ids]\n",
    "\n",
    "# Update original files\n",
    "train_data['images'].extend(extra_train)\n",
    "train_data['annotations'].extend(extra_train_annotations)\n",
    "\n",
    "valid_data['images'].extend(extra_val)\n",
    "valid_data['annotations'].extend(extra_val_annotations)\n",
    "\n",
    "test_data['images'] = test_images\n",
    "test_data['annotations'] = test_annotations\n",
    "\n",
    "# Save back to disk\n",
    "with open(train_path, 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "with open(valid_path, 'w') as f:\n",
    "    json.dump(valid_data, f)\n",
    "\n",
    "with open(test_path, 'w') as f:\n",
    "    json.dump(test_data, f)\n",
    "\n",
    "print(\"✅ Split complete. Test now has 10 images. Others redistributed to train and valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified htc_r50_fpn_1x_artifact.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = './htc_r50_fpn_1x_coco.py'\n",
    "\n",
    "# 1. Modify dataset classes\n",
    "classes = ('artefact',)\n",
    "\n",
    "# 2. Update dataset paths\n",
    "data_root = '/Users/jbm/Documents/DSAN_6500/WatchdogAI/data_artifacts/'\n",
    "# data = dict(\n",
    "#     samples_per_gpu=2,\n",
    "#     workers_per_gpu=2,\n",
    "#     train=dict(\n",
    "#         type='CocoDataset',\n",
    "#         ann_file=data_root + 'train/_annotations.coco.json',\n",
    "#         img_prefix=data_root + 'train/',\n",
    "#         classes=classes\n",
    "#     ),\n",
    "#     val=dict(\n",
    "#         type='CocoDataset',\n",
    "#         ann_file=data_root + 'valid/_annotations.coco.json',\n",
    "#         img_prefix=data_root + 'valid/',\n",
    "#         classes=classes\n",
    "#     ),\n",
    "#     test=dict(\n",
    "#         type='CocoDataset',\n",
    "#         ann_file=data_root + 'test/_annotations.coco.json',\n",
    "#         img_prefix=data_root + 'test/',\n",
    "#         classes=classes\n",
    "#     )\n",
    "# )\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
    "    dataset=dict(\n",
    "        type='CocoDataset',\n",
    "        data_root=data_root,\n",
    "        ann_file='train/_annotations.coco.json',\n",
    "        data_prefix=dict(img='train/'),\n",
    "        metainfo=dict(classes=classes),\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
    "            dict(type='RandomFlip', prob=0.5),\n",
    "\n",
    "            # AutoAugment with scale changes — simulates variable resolution\n",
    "            dict(\n",
    "                type='AutoAugment',\n",
    "                policies=[\n",
    "                    [dict(type='Resize', scale=(1333, 640), keep_ratio=True)],\n",
    "                    [dict(type='Resize', scale=(1333, 800), keep_ratio=True)],\n",
    "                    [dict(type='Resize', scale=(1333, 960), keep_ratio=True)]\n",
    "                ]\n",
    "            ),\n",
    "\n",
    "            # Mild brightness/contrast jitter — simulates different lighting\n",
    "            dict(\n",
    "                type='PhotoMetricDistortion',\n",
    "                brightness_delta=16,\n",
    "                contrast_range=(0.9, 1.1),\n",
    "                saturation_range=(0.95, 1.05),\n",
    "                hue_delta=4\n",
    "            ),\n",
    "\n",
    "            dict(type='PackDetInputs')\n",
    "        ]\n",
    "        # pipeline=[\n",
    "        #     dict(type='LoadImageFromFile'),\n",
    "        #     dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
    "        #     dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
    "        #     dict(type='RandomFlip', prob=0.5),\n",
    "        #     dict(type='PhotoMetricDistortion'),\n",
    "        #     dict(type='PackDetInputs')\n",
    "        # ]\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type='CocoDataset',\n",
    "        data_root=data_root,\n",
    "        ann_file='valid/_annotations.coco.json',\n",
    "        data_prefix=dict(img='valid/'),\n",
    "        metainfo=dict(classes=classes),\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
    "            dict(type='LoadAnnotations', with_bbox=True, with_mask=False),\n",
    "            dict(\n",
    "                type='PackDetInputs',\n",
    "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor'))\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "\n",
    "val_evaluator = dict(\n",
    "    type='CocoMetric',\n",
    "    ann_file=data_root + 'valid/_annotations.coco.json',\n",
    "    metric=['bbox']\n",
    ")\n",
    "\n",
    "test_evaluator = val_evaluator\n",
    "\n",
    "# 3. Adjust model to match 1 class\n",
    "model = dict(\n",
    "    backbone=dict(\n",
    "    frozen_stages=1  # maybe 2 later (for me to check after training)\n",
    "    ),\n",
    "    roi_head=dict(\n",
    "        bbox_head=[\n",
    "            dict(type='Shared2FCBBoxHead', num_classes=1),\n",
    "            dict(type='Shared2FCBBoxHead', num_classes=1),\n",
    "            dict(type='Shared2FCBBoxHead', num_classes=1)\n",
    "        ]\n",
    "    ),\n",
    "\n",
    "    rpn_head=dict(\n",
    "        type='RPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[.0, .0, .0, .0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0),\n",
    "        test_cfg=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=1000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=1000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0\n",
    "        ),\n",
    "        rcnn=dict(\n",
    "            score_thr=0.05,\n",
    "            nms=dict(type='nms', iou_threshold=0.5),\n",
    "            max_per_img=100\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    train_cfg=dict(\n",
    "        rpn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.3,\n",
    "                min_pos_iou=0.3,\n",
    "                ignore_iof_thr=-1\n",
    "            ),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=256,\n",
    "                pos_fraction=0.5,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=False\n",
    "            ),\n",
    "            allowed_border=0,\n",
    "            pos_weight=-1,\n",
    "            debug=False,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            nms_pre=2000,\n",
    "            max_per_img=1000,\n",
    "            min_bbox_size=0\n",
    "        ),\n",
    "        rpn_proposal=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=1000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0\n",
    "        ),\n",
    "        rcnn=[\n",
    "            dict(\n",
    "                assigner=dict(\n",
    "                    type='MaxIoUAssigner',\n",
    "                    pos_iou_thr=0.5,\n",
    "                    neg_iou_thr=0.5,\n",
    "                    min_pos_iou=0.5,\n",
    "                    ignore_iof_thr=-1),\n",
    "                sampler=dict(\n",
    "                    type='RandomSampler',\n",
    "                    num=512,\n",
    "                    pos_fraction=0.25,\n",
    "                    neg_pos_ub=-1,\n",
    "                    add_gt_as_proposals=True),\n",
    "                mask_size=28,\n",
    "                pos_weight=-1,\n",
    "                debug=False\n",
    "            ) for _ in range(3)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "model['train_cfg'] = dict(\n",
    "    rpn=dict(\n",
    "        nms=dict(type='nms', iou_threshold=0.7)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4. Shorten training (for Mac)\n",
    "# runner = dict(type='EpochBasedRunner', max_epochs=6)\n",
    "\n",
    "# Early stopping but on iterations not epochs\n",
    "train_cfg = dict(\n",
    "    type='IterBasedTrainLoop', max_iters=10000, val_interval=150\n",
    ")\n",
    "\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "\n",
    "# Add early stopping hook\n",
    "custom_hooks = [\n",
    "    dict(\n",
    "        type='EarlyStoppingHook',\n",
    "        monitor='coco/bbox_mAP',  # or 'bbox_mAP_50', check your val_evaluator logs\n",
    "        rule='greater',  # because higher mAP is better\n",
    "        patience=30  # stops training if no improvement in X val intervals\n",
    "    )\n",
    "]\n",
    "\n",
    "custom_hooks += [\n",
    "    dict(\n",
    "        type='VisualizationHook',\n",
    "        interval=0,  # only do at the very end\n",
    "        draw=True,\n",
    "        test_out_dir='work_dirs/htc_r50_artifact/vis_results'  # saves images here\n",
    "    )\n",
    "]\n",
    "\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook',\n",
    "        interval=1000,  # How often to save\n",
    "        save_best='coco/bbox_mAP',  # Metric to track for best\n",
    "        rule='greater',  # Maximize the metric\n",
    "        max_keep_ckpts=1  # Only keep best to save space\n",
    "    ),\n",
    "    logger=dict(type='LoggerHook', interval=50)\n",
    ")\n",
    "\n",
    "visualizer = dict(\n",
    "    type='DetLocalVisualizer',\n",
    "    vis_backends=[dict(type='LocalVisBackend')],\n",
    "    name='vis'\n",
    ")\n",
    "\n",
    "# 5. Set working directory\n",
    "work_dir = './work_dirs/htc_r50_artifact'\n",
    "load_from = 'checkpoints/htc_r50.pth'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
